{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFJ0xnFb3mYucPZGQq9r/M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anthony-Tafoya/Form_Trainer/blob/main/eMERGE_MIMICIV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MIMICIV eMERGE Diabetes Dataset Generator\n",
        "\n",
        "Goal: The goal of this colab is to filter for patients with type-2 diabetes\n",
        "\n",
        "**MIMICIV is accessed through Google BigQuery so in order to test this on your own, you need to replace the project_id in the client method and authenticate with your own Google account**\n",
        "\n",
        "Method: eMERGE is a reliable and interpretable rule-based algorithm for the identification of T2D cases and controls in EHRs. The logic was based on the flow chart and paper below (please refer to the flow chart in the paper to get a better idea of the algorithm)\n",
        "\n",
        "Overall, 11422 patients were filtered compare dot the 12375 patients in the paper and I welcome suggestions on how to improve the pipeline!\n",
        "\n",
        "Afterward, I parsed the MIMICIV for patients eligible for my diabetes dataset and use GloVe 6b for the doctor's embeddings\n",
        "\n",
        "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10283086/pdf/2281.pdf"
      ],
      "metadata": {
        "id": "kreeier8YlhD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQtjubc7l_Iv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc590d5-6de1-4ea5-fc66-0923bb2f5eac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.10/dist-packages (3.12.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.47.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (1.60.0)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.11.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (1.23.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.7.0)\n",
            "Requirement already satisfied: packaging>=20.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (23.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (3.20.3)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.8.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.31.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (1.62.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (2.17.3)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (1.48.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery) (1.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2023.11.17)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (0.5.1)\n",
            "Requirement already satisfied: pandas_gbq in /usr/local/lib/python3.10/dist-packages (0.19.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (67.7.2)\n",
            "Requirement already satisfied: db-dtypes<2.0.0,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (1.5.3)\n",
            "Requirement already satisfied: pyarrow>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (10.0.1)\n",
            "Requirement already satisfied: pydata-google-auth>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (1.8.2)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.10.2 in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (2.11.1)\n",
            "Requirement already satisfied: google-auth>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (1.2.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5 in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (3.12.0)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage<3.0.0dev,>=2.16.2 in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (2.24.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from db-dtypes<2.0.0,>=1.0.4->pandas_gbq) (23.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (1.62.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.13.0->pandas_gbq) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.13.0->pandas_gbq) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.13.0->pandas_gbq) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.13.0->pandas_gbq) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib>=0.7.0->pandas_gbq) (1.3.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.47.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (1.60.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (1.23.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (2.7.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->pandas_gbq) (2023.3.post1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (1.48.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.13.0->pandas_gbq) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (2023.11.17)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.7.0->pandas_gbq) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "# Install the BigQuery client library\n",
        "!pip install google-cloud-bigquery\n",
        "!pip install pandas_gbq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all the necessayr packages\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas_gbq\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.path as path\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "from IPython.display import display, HTML"
      ],
      "metadata": {
        "id": "qYznRCbnKdKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_diagnosis(client):\n",
        "    # Define the SQL queries as a Python string\n",
        "    na_sql =  \"\"\"\n",
        "        SELECT * FROM `physionet-data.mimiciv_hosp.diagnoses_icd`\n",
        "        WHERE\n",
        "            NOT REGEXP_CONTAINS(icd_code, r'250[0-9]*[02]$') AND -- Excludes for ICD Code Diabetes Type II\n",
        "            NOT REGEXP_CONTAINS(icd_code, r'250[0-9]*[13]$')     -- Excludes for ICD Code Diabetes Type I\n",
        "        \"\"\"\n",
        "\n",
        "    t2_sql = \"\"\"\n",
        "        SELECT * FROM `physionet-data.mimiciv_hosp.diagnoses_icd`\n",
        "        WHERE\n",
        "            REGEXP_CONTAINS(icd_code, r'250[0-9]*[02]$') AND -- Includes for ICD Code Diabetes Type II\n",
        "            NOT REGEXP_CONTAINS(icd_code, r'250[0-9]*[13]$') AND -- Excludes for ICD Code Diabetes Type I\n",
        "            icd_code NOT IN ('25010', '25012') -- Excluding 250.10 and 250.12\n",
        "        \"\"\"\n",
        "\n",
        "    # Execute the query for no diabetes diagnosis\n",
        "    na_query_job = client.query(na_sql)\n",
        "    na_results_df = na_query_job.to_dataframe()\n",
        "\n",
        "    # Execute the query for t2 diagnosis\n",
        "    t2_query_job = client.query(t2_sql)\n",
        "    t2_results_df = t2_query_job.to_dataframe()\n",
        "\n",
        "    na_ids = set(na_results_df['subject_id'])\n",
        "    t2_ids = set(t2_results_df['subject_id'])\n",
        "\n",
        "    return na_ids, t2_ids"
      ],
      "metadata": {
        "id": "E8StCN8MmDwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_t1_prescriptions(client, ids):\n",
        "    # T1DM medications\n",
        "    t1_medications = ['insulin', 'pramlintide']\n",
        "\n",
        "    # Lowercase and format the list for SQL query\n",
        "    formatted_meds_list = \"', '\".join([med.lower() for med in t1_medications])\n",
        "\n",
        "    # Construct the SQL query\n",
        "    t1_query = f\"\"\"\n",
        "    SELECT DISTINCT subject_id\n",
        "    FROM `physionet-data.mimiciv_hosp.prescriptions`\n",
        "    WHERE LOWER(drug) IN ('{formatted_meds_list}')\n",
        "    \"\"\"\n",
        "    t1_query_job = client.query(t1_query)\n",
        "    t1_results_df = t1_query_job.to_dataframe()\n",
        "\n",
        "    # Convert result to intersecting set for efficient processing\n",
        "    satisfied_ids = set(t1_results_df['subject_id']) & ids\n",
        "\n",
        "    # Set operation in Python to find not satisfied subject_ids\n",
        "    not_satisfied_ids = ids - satisfied_ids\n",
        "\n",
        "    return not_satisfied_ids, satisfied_ids\n"
      ],
      "metadata": {
        "id": "K-oYwtTwmGFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_t2_prescriptions(client, ids):\n",
        "    # T2DM medications\n",
        "    t2_medications = [\n",
        "        \"acetohexamide\", \"tolazamide\", \"chlorpropamide\", \"glipizide\", \"glyburide\",\n",
        "        \"glimepiride\", \"repaglinide\", \"nateglinide\", \"metformin\", \"rosiglitazone\",\n",
        "        \"pioglitazone\", \"troglitazone\", \"acarbose\", \"miglitol\", \"sitagliptin\",\n",
        "        \"exenatide\", \"alogliptin\", \"saxagliptin\", \"linagliptin\", \"ertugliflozin\",\n",
        "        \"dapagliflozin\", \"empagliflozin\", \"canagliflozin\", \"dulaglutide\", \"semaglutide\",\n",
        "        \"liraglutide\", \"lixisenatide\", \"colesevelam\", \"bromocriptine\"\n",
        "    ]\n",
        "\n",
        "    # Lowercase and format the list for SQL query\n",
        "    formatted_meds_list = \"', '\".join([med.lower() for med in t2_medications])\n",
        "\n",
        "    # Construct the SQL query\n",
        "    t2_query = f\"\"\"\n",
        "    SELECT DISTINCT subject_id\n",
        "    FROM `physionet-data.mimiciv_hosp.prescriptions`\n",
        "    WHERE LOWER(drug) IN ('{formatted_meds_list}')\n",
        "    \"\"\"\n",
        "    t2_query_job = client.query(t2_query)\n",
        "    t2_results_df = t2_query_job.to_dataframe()\n",
        "\n",
        "    # Convert result to intersecting set for efficient processing\n",
        "    satisfied_ids = set(t2_results_df['subject_id']) & ids\n",
        "\n",
        "    # Set operation in Python to find not satisfied subject_ids\n",
        "    not_satisfied_ids = ids - satisfied_ids\n",
        "\n",
        "    return not_satisfied_ids, satisfied_ids\n"
      ],
      "metadata": {
        "id": "sMzcntgVLlHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def connect_to_MIMIC():\n",
        "    # Construct a BigQuery client object\n",
        "    auth.authenticate_user()\n",
        "    print('Authenticated')\n",
        "    project_id = 'agile-kite-406408'\n",
        "    client = bigquery.Client(project=project_id)\n",
        "    return client"
      ],
      "metadata": {
        "id": "FB8IX20lmIpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make BigQuery connection to MIMIC\n",
        "client = connect_to_MIMIC()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inOJjyaqmLOz",
        "outputId": "1e6c91d3-c20a-4c4e-9d99-10862abc2f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter by diagnosis\n",
        "na_diagnosed, t2_diagnosed = filter_diagnosis(client)"
      ],
      "metadata": {
        "id": "wWjnIMLFOL28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the length for debugging\n",
        "print(len(na_diagnosed),len(t2_diagnosed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RIM2RSFlQw8",
        "outputId": "ea07f2a9-5280-4217-d6f5-f581d2de0b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180618 23092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter by mediciation\n",
        "\"\"\"\n",
        "These methods are structrued by (not included, included)\n",
        "At the end of these calls, the following will be relevant\n",
        "\n",
        "ud_abn_lab - Undiagnosed patients that need abnormal lab analysis\n",
        "d_abn_lab - Diagnosed patients that need abnormal lab analysis\n",
        "t1_medicine - Diagnosed patients who have a t1 medicine\n",
        "t1t2_medicine - Diagnosed patients who have both t1 and t2 medicines\n",
        "t2_medicine - Diagnosed patients who have a t2 medicine\n",
        "\"\"\"\n",
        "_, ud_abn_lab = filter_t2_prescriptions(client, na_diagnosed)\n",
        "na_medicine, t1_medicine = filter_t1_prescriptions(client, t2_diagnosed)\n",
        "d_abn_lab, t2_medicine = filter_t2_prescriptions(client, na_medicine)\n",
        "t1_medicine, t1t2_medicine = filter_t2_prescriptions(client, t1_medicine)"
      ],
      "metadata": {
        "id": "MSE1REvmOQQP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "fea80918-c678-4cd3-8668-99bbffc0989c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-186-cf716a350413>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mt2_medicine\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mDiagnosed\u001b[0m \u001b[0mpatients\u001b[0m \u001b[0mwho\u001b[0m \u001b[0mhave\u001b[0m \u001b[0ma\u001b[0m \u001b[0mt2\u001b[0m \u001b[0mmedicine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \"\"\"\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mud_abn_lab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_t2_prescriptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_diagnosed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mna_medicine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1_medicine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_t1_prescriptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2_diagnosed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0md_abn_lab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2_medicine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_t2_prescriptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_medicine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-181-ebf5113554e4>\u001b[0m in \u001b[0;36mfilter_t2_prescriptions\u001b[0;34m(client, ids)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \"\"\"\n\u001b[1;32m     21\u001b[0m     \u001b[0mt2_query_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mt2_results_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt2_query_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Convert result to intersecting set for efficient processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mto_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \"\"\"\n\u001b[1;32m   1860\u001b[0m         \u001b[0mquery_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait_for_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         return query_result.to_dataframe(\n\u001b[0m\u001b[1;32m   1862\u001b[0m             \u001b[0mbqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbqstorage_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m             \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/bigquery/table.py\u001b[0m in \u001b[0;36mto_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype)\u001b[0m\n\u001b[1;32m   2153\u001b[0m             \u001b[0mbqstorage_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m         record_batch = self.to_arrow(\n\u001b[0m\u001b[1;32m   2156\u001b[0m             \u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m             \u001b[0mbqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbqstorage_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/bigquery/table.py\u001b[0m in \u001b[0;36mto_arrow\u001b[0;34m(self, progress_bar_type, bqstorage_client, create_bqstorage_client)\u001b[0m\n\u001b[1;32m   1823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m             \u001b[0mrecord_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1825\u001b[0;31m             for record_batch in self.to_arrow_iterable(\n\u001b[0m\u001b[1;32m   1826\u001b[0m                 \u001b[0mbqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbqstorage_client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1827\u001b[0m             ):\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/bigquery/table.py\u001b[0m in \u001b[0;36m_to_page_iterable\u001b[0;34m(self, bqstorage_download, tabledata_list_download, bqstorage_client)\u001b[0m\n\u001b[1;32m   1686\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mtabledata_list_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m         )\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mresult_pages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m     def to_arrow_iterable(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/bigquery/_pandas_helpers.py\u001b[0m in \u001b[0;36m_download_table_bqstorage\u001b[0;34m(project_id, table, bqstorage_client, preserve_order, selected_fields, page_to_item, max_queue_size)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m                     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworker_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_PROGRESS_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: NO COVER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the length for debugging\n",
        "print(len(na_medicine), len(t1_medicine), len(t2_medicine), len(t1t2_medicine), len(ud_abn_lab), len(d_abn_lab))"
      ],
      "metadata": {
        "id": "74t7oLp8YvTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_medicine_by_date(client, ids):\n",
        "    # T1DM medications\n",
        "    t1_medications = ['insulin', 'pramlintide']\n",
        "\n",
        "    # T2DM medications\n",
        "    t2_medications = [\n",
        "        \"acetohexamide\", \"tolazamide\", \"chlorpropamide\", \"glipizide\", \"glyburide\",\n",
        "        \"glimepiride\", \"repaglinide\", \"nateglinide\", \"metformin\", \"rosiglitazone\",\n",
        "        \"pioglitazone\", \"troglitazone\", \"acarbose\", \"miglitol\", \"sitagliptin\",\n",
        "        \"exenatide\", \"alogliptin\", \"saxagliptin\", \"linagliptin\", \"ertugliflozin\",\n",
        "        \"dapagliflozin\", \"empagliflozin\", \"canagliflozin\", \"dulaglutide\", \"semaglutide\",\n",
        "        \"liraglutide\", \"lixisenatide\", \"colesevelam\", \"bromocriptine\"\n",
        "    ]\n",
        "\n",
        "    # Lowercase and format the list for SQL query\n",
        "    formatted_t1_meds_list = \"', '\".join([med.lower() for med in t1_medications])\n",
        "    formatted_t2_meds_list = \"', '\".join([med.lower() for med in t2_medications])\n",
        "\n",
        "    # Construct the SQL query that compares earliest dates\n",
        "    query = f\"\"\"\n",
        "    SELECT DISTINCT t2.subject_id\n",
        "    FROM (\n",
        "        SELECT subject_id, MIN(starttime) as earliest_t2_time\n",
        "        FROM `physionet-data.mimiciv_hosp.prescriptions`\n",
        "        WHERE LOWER(drug) IN ('{formatted_t2_meds_list}')\n",
        "        GROUP BY subject_id\n",
        "    ) t2\n",
        "    INNER JOIN (\n",
        "        SELECT subject_id, MIN(starttime) as earliest_t1_time\n",
        "        FROM `physionet-data.mimiciv_hosp.prescriptions`\n",
        "        WHERE LOWER(drug) IN ('{formatted_t1_meds_list}')\n",
        "        GROUP BY subject_id\n",
        "    ) t1 ON t2.subject_id = t1.subject_id\n",
        "    WHERE t2.earliest_t2_time < t1.earliest_t1_time;\n",
        "    \"\"\"\n",
        "\n",
        "    query_job = client.query(query)\n",
        "    results_df = query_job.to_dataframe()\n",
        "\n",
        "    # Convert result to intersecting set for efficient processing\n",
        "    satisfied_ids = set(results_df['subject_id']) & ids\n",
        "\n",
        "    # Set operation in Python to find not satisfied subject_ids\n",
        "    not_satisfied_ids = ids - satisfied_ids\n",
        "\n",
        "    return not_satisfied_ids, satisfied_ids"
      ],
      "metadata": {
        "id": "AQZKoNBCbsLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter by date\n",
        "\"\"\"\n",
        "Given the ids of a patient with a t2 diagnosis, t1 medicine prescription,\n",
        "and t2 medicine prescription, we only want to keep the ones where the t2\n",
        "was prescribed at an earlier start time than t1\n",
        "\"\"\"\n",
        "test, t2_b_t1_medicine = filter_medicine_by_date(client, t1t2_medicine)"
      ],
      "metadata": {
        "id": "_lLi_VUIkjtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the length for debugging\n",
        "print(len(t2_b_t1_medicine))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlewfHNPlY-j",
        "outputId": "ddbb3ec6-288e-4f19-9a32-478e13447a49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_t2_count_diagnoses(client, ids):\n",
        "    # SQL query to select subject_ids with 2 or more T2DM diagnoses based on ICD codes\n",
        "    query = \"\"\"\n",
        "    SELECT subject_id, COUNT(*) as num_t2dm_diagnoses\n",
        "    FROM `physionet-data.mimiciv_hosp.diagnoses_icd`\n",
        "    WHERE\n",
        "      REGEXP_CONTAINS(icd_code, r'250[0-9]*[02]$') -- Includes ICD codes for T2DM\n",
        "      AND icd_code NOT IN ('25010', '25012') -- Excludes specific ICD codes for T2DM\n",
        "    GROUP BY subject_id\n",
        "    HAVING num_t2dm_diagnoses >= 2\n",
        "    \"\"\"\n",
        "\n",
        "    # Execute the query\n",
        "    query_job = client.query(query)\n",
        "    results_df = query_job.to_dataframe()\n",
        "\n",
        "    # Convert result to intersecting set for efficient processing\n",
        "    satisfied_ids = set(results_df['subject_id']) & ids\n",
        "\n",
        "    # Set operation in Python to find not satisfied subject_ids\n",
        "    not_satisfied_ids = ids - satisfied_ids\n",
        "\n",
        "    return not_satisfied_ids, satisfied_ids"
      ],
      "metadata": {
        "id": "gHBZNBianjuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep diagnosed patients who have no t2 medicine if they have >= 2 diagnosis\n",
        "_, twod_t1_medicine = filter_t2_count_diagnoses(client, t1_medicine)"
      ],
      "metadata": {
        "id": "s_V3DebppZxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the length for debugging\n",
        "print(len(twod_t1_medicine))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyljXPVkp1u3",
        "outputId": "6e25bd59-f739-47a5-ebe4-fc12b4a0db79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_abnormal_chartevents_values(client, ids):\n",
        "    # SQL query to select subject_ids with abnormal DM-related chart values and filter out outliers\n",
        "    query = \"\"\"\n",
        "    WITH max_glucose_per_patient AS (\n",
        "        SELECT subject_id, MAX(valuenum) as max_glucose -- Groups glucose values to take max\n",
        "        FROM `physionet-data.mimiciv_icu.chartevents`\n",
        "        WHERE itemid IN (220621, 225664, 226537) -- These item IDs are assumed to be fasting glucose measurements\n",
        "        GROUP BY subject_id\n",
        "    ),\n",
        "    abnormal_glucose AS (\n",
        "        SELECT subject_id\n",
        "        FROM max_glucose_per_patient\n",
        "        WHERE max_glucose >= 125 -- Selects patients with a max fasting glucose ≥ 125 mg/dl\n",
        "        AND max_glucose < 1000 -- Selects patients with a max fasting glucose that are not outliers ≥ 1000 mg/dl\n",
        "    )\n",
        "    SELECT DISTINCT subject_id\n",
        "    FROM abnormal_glucose\n",
        "    \"\"\"\n",
        "\n",
        "    # Execute the query\n",
        "    query_job = client.query(query)\n",
        "    results_df = query_job.to_dataframe()\n",
        "\n",
        "    # Convert result to a set for efficient processing\n",
        "    abnormal_ids = set(results_df['subject_id'])\n",
        "\n",
        "    # Set operation in Python to find satisfied and not satisfied subject_ids\n",
        "    satisfied_ids = abnormal_ids & ids\n",
        "    not_satisfied_ids = ids - satisfied_ids\n",
        "\n",
        "    return not_satisfied_ids, satisfied_ids\n",
        "\n",
        "def filter_abnormal_labevents_values(client, ids):\n",
        "    # SQL query to select subject_ids with abnormal DM-related lab values\n",
        "    query = \"\"\"\n",
        "    WITH max_glucose_per_patient AS (\n",
        "        SELECT subject_id, MAX(valuenum) as max_glucose -- Groups glucose values to take max\n",
        "        FROM `physionet-data.mimiciv_hosp.labevents`\n",
        "        WHERE itemid IN (50809, 50931, 52569) -- These item IDs are assumed to be fasting glucose measurements\n",
        "        GROUP BY subject_id\n",
        "    ),\n",
        "    abnormal_glucose AS (\n",
        "        SELECT subject_id\n",
        "        FROM max_glucose_per_patient\n",
        "        WHERE max_glucose >= 125 AND max_glucose < 1000 -- Selects patients with a max fasting glucose ≥ 125 mg/dl and below 1000 mg/dl\n",
        "    ),\n",
        "    abnormal_hba1c AS (\n",
        "        SELECT subject_id\n",
        "        FROM `physionet-data.mimiciv_hosp.labevents`\n",
        "        WHERE itemid = 50852 AND valuenum >= 6.5  -- Selects patients with a Hba1c <  6.5%\n",
        "    ),\n",
        "    combined_abnormal AS (\n",
        "        SELECT subject_id FROM abnormal_glucose\n",
        "        UNION DISTINCT\n",
        "        SELECT subject_id FROM abnormal_hba1c\n",
        "    )\n",
        "    SELECT subject_id\n",
        "    FROM combined_abnormal;\n",
        "    \"\"\"\n",
        "\n",
        "    # Execute the query\n",
        "    query_job = client.query(query)\n",
        "    results_df = query_job.to_dataframe()\n",
        "\n",
        "    # Convert result to a set for efficient processing\n",
        "    abnormal_ids = set(results_df['subject_id'])\n",
        "\n",
        "    # Set operation in Python to find satisfied and not satisfied subject_ids\n",
        "    satisfied_ids = abnormal_ids & ids\n",
        "    not_satisfied_ids = ids - satisfied_ids\n",
        "\n",
        "    return not_satisfied_ids, satisfied_ids"
      ],
      "metadata": {
        "id": "fMqbIXb2qPAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"For patients who do have T2 diagnosis or T2 medicine, keep\n",
        "   if they have an abnormal lab test which could mean one of\n",
        "   the two conditions:\n",
        "\n",
        "   1) Patient has a max fasting glucose ≥ 125 mg/dl and < 1000 mg/dl\n",
        "   2) Patient has a % Hemoglobin A1c ≥ 6.5%\"\"\"\n",
        "\n",
        "# Filtering the abnormal labs for undiagnosed patients and deleting duplicates with sets\n",
        "print(len(ud_abn_lab))\n",
        "_, ud_abn_lab_chart = filter_abnormal_chartevents_values(client, ud_abn_lab)\n",
        "_, ud_abn_lab_lab = filter_abnormal_labevents_values(client, ud_abn_lab)\n",
        "ud_abn_lab = ud_abn_lab_chart & ud_abn_lab_lab\n",
        "\n",
        "# Filtering the abnormal labs for diagnosed patients and deleting duplicates with sets\n",
        "print(len(d_abn_lab))\n",
        "_, d_abn_lab_chart = filter_abnormal_chartevents_values(client, d_abn_lab)\n",
        "_, d_abn_lab_lab = filter_abnormal_labevents_values(client, d_abn_lab)\n",
        "d_abn_lab = d_abn_lab_chart & d_abn_lab_lab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFYVhNpcJONl",
        "outputId": "8b453732-747e-4d2b-9080-3f66d9314b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5197\n",
            "2790\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the length for debugging\n",
        "print(len(ud_abn_lab), len(d_abn_lab))"
      ],
      "metadata": {
        "id": "IpLDz9_rWMzk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1acd5e28-c0ef-4453-ab7b-76345ad8cec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2498 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining patients with abnormal tests\n",
        "t2_patient_ids = ud_abn_lab.union(d_abn_lab)\n",
        "\n",
        "# Adding patients with t2 medicine before t1\n",
        "t2_patient_ids = t2_patient_ids.union(t2_b_t1_medicine)\n",
        "\n",
        "# Adding patients with t1 medicine but two diagnosis\n",
        "t2_patient_ids = t2_patient_ids.union(twod_t1_medicine)\n",
        "\n",
        "# Adding patients with t2 medicine and t2 diagnosis\n",
        "t2_patient_ids = t2_patient_ids.union(t2_medicine)"
      ],
      "metadata": {
        "id": "QTuXCuHCXKUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the length for debugging\n",
        "print(len(t2_patient_ids))\n",
        "t2_diabetes_ids = t2_patient_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB9MrANmYaSF",
        "outputId": "a8107bbe-d84a-4e2e-842f-20b61522d4ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"This set of code constructs the diabetes dataset\"\"\"\n",
        "def extracting_notes(client, ids):\n",
        "  # SQL Query to extract the id, gender, and age\n",
        "  query = f\"\"\"\n",
        "    SELECT DISTINCT subject_id,\n",
        "       FIRST_VALUE(text) OVER (PARTITION BY subject_id ORDER BY charttime) AS first_note\n",
        "       FROM `physionet-data.mimiciv_note.discharge`\n",
        "    \"\"\"\n",
        "\n",
        "  # Execute the query\n",
        "  query_job = client.query(query)\n",
        "  results_df = query_job.to_dataframe()\n",
        "\n",
        "  # Fitlering for patients with diabetes\n",
        "  filtered_df = results_df[results_df['subject_id'].isin(ids)]\n",
        "\n",
        "  return filtered_df\n",
        "\n",
        "def extracting_treatments(client, ids):\n",
        "  # SQL Query to extract T2DM treatment\n",
        "    t2_medications = [\n",
        "        \"acetohexamide\", \"tolazamide\", \"chlorpropamide\", \"glipizide\", \"glyburide\",\n",
        "        \"glimepiride\", \"repaglinide\", \"nateglinide\", \"metformin\", \"rosiglitazone\",\n",
        "        \"pioglitazone\", \"troglitazone\", \"acarbose\", \"miglitol\", \"sitagliptin\",\n",
        "        \"exenatide\", \"alogliptin\", \"saxagliptin\", \"linagliptin\", \"ertugliflozin\",\n",
        "        \"dapagliflozin\", \"empagliflozin\", \"canagliflozin\", \"dulaglutide\", \"semaglutide\",\n",
        "        \"liraglutide\", \"lixisenatide\", \"colesevelam\", \"bromocriptine\"\n",
        "    ]\n",
        "\n",
        "    # Lowercase and format the list for SQL query\n",
        "    formatted_t2_meds_list = \"', '\".join([med.lower() for med in t2_medications])\n",
        "\n",
        "    # Construct the SQL query that retrieves prescriptions\n",
        "    query = f\"\"\"\n",
        "        SELECT subject_id, STRING_AGG(DISTINCT LOWER(drug), ', ') AS prescriptions\n",
        "          FROM `physionet-data.mimiciv_hosp.prescriptions`\n",
        "          WHERE LOWER(drug) IN ('{formatted_t2_meds_list}')\n",
        "          GROUP BY subject_id\n",
        "        \"\"\"\n",
        "\n",
        "    # Execute the query\n",
        "    query_job = client.query(query)\n",
        "    results_df = query_job.to_dataframe()\n",
        "\n",
        "    # Filter the query\n",
        "    filtered_df = results_df[results_df['subject_id'].isin(ids)]\n",
        "\n",
        "    return filtered_df\n",
        "\n",
        "def extracting_hba1c(client, ids):\n",
        "    # SQL Query to fetch all HbA1c values for each subject.\n",
        "    query = \"\"\"\n",
        "    SELECT subject_id, valuenum, charttime\n",
        "    FROM `physionet-data.mimiciv_hosp.labevents`\n",
        "    WHERE itemid = 50852\n",
        "    ORDER BY subject_id, charttime DESC\n",
        "    \"\"\"\n",
        "\n",
        "    # Execute the query\n",
        "    query_job = client.query(query)\n",
        "    results_df = query_job.to_dataframe()\n",
        "\n",
        "    # Dataframe preprocessing\n",
        "    results_df['charttime'] = pd.to_datetime(results_df['charttime'])\n",
        "    measurement_counts = results_df.groupby('subject_id').size()\n",
        "\n",
        "    # Get the most recent value for each subject\n",
        "    most_recent_values = results_df.groupby('subject_id').first().reset_index()\n",
        "\n",
        "    # Calculate percentiles for each subject, excluding the most recent value\n",
        "    percentiles = results_df.groupby('subject_id')['valuenum'].apply(\n",
        "        lambda x: x.iloc[1:].quantile([0.25, 0.5, 0.75]) if len(x) > 1 else pd.Series(['NaN'] * 3, index=[0.25, 0.5, 0.75])\n",
        "    ).unstack()\n",
        "\n",
        "    # Combine the most recent values with the percentiles and cleanup dataset\n",
        "    final_df = most_recent_values.merge(percentiles, on='subject_id')\n",
        "    filtered_df = final_df[final_df['subject_id'].isin(ids)]\n",
        "    filtered_df = filtered_df.rename(columns={'valuenum': 'recent_hba1c'})\n",
        "    filtered_df.drop('charttime', axis=1, inplace=True)\n",
        "\n",
        "    return filtered_df\n",
        "\n",
        "def extracting_age_gender(client, ids):\n",
        "  # SQL Query to extract the id, gender, and age\n",
        "  query = f\"\"\"\n",
        "    SELECT subject_id, gender, anchor_age\n",
        "    FROM `physionet-data.mimiciv_hosp.patients`\n",
        "    \"\"\"\n",
        "\n",
        "  # Execute the query\n",
        "  query_job = client.query(query)\n",
        "  results_df = query_job.to_dataframe()\n",
        "\n",
        "  # Fitlering for patients with diabetes\n",
        "  filtered_df = results_df[results_df['subject_id'].isin(ids)]\n",
        "\n",
        "  return filtered_df\n",
        "\n",
        "def extracting_race(client, ids):\n",
        "  # SQL query to extract patient race\n",
        "  query = f\"\"\"\n",
        "      SELECT DISTINCT subject_id,\n",
        "      FIRST_VALUE(race) OVER (PARTITION BY subject_id ORDER BY admittime) AS first_race\n",
        "      FROM `physionet-data.mimiciv_hosp.admissions`;\n",
        "    \"\"\"\n",
        "\n",
        "  # Execute the query\n",
        "  query_job = client.query(query)\n",
        "  results_df = query_job.to_dataframe()\n",
        "\n",
        "  # Filtering for patients with diabetes\n",
        "  filtered_df = results_df[results_df['subject_id'].isin(ids)]\n",
        "\n",
        "  return filtered_df"
      ],
      "metadata": {
        "id": "pP78WBj_JHPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract patient demographics\n",
        "age_gender = extracting_age_gender(client, t2_diabetes_ids)\n",
        "race = extracting_race(client, t2_diabetes_ids)\n",
        "\n",
        "# Merge the DataFrames based on subject_ds\n",
        "age_gender_race = age_gender.merge(race, on='subject_id')"
      ],
      "metadata": {
        "id": "mZbWz1YgREkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract patient hemoglobin values\n",
        "hba1c = extracting_hba1c(client, t2_diabetes_ids)\n",
        "age_gender_race_hba1c = age_gender_race.merge(hba1c, on='subject_id')"
      ],
      "metadata": {
        "id": "2fNAjFuKmnCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pJWFSIYRxsc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting treatment history\n",
        "treatments = extracting_treatments(client, t2_diabetes_ids)\n",
        "\n",
        "# Assuming age_gender_race_hba1c and treatments are already defined DataFrames\n",
        "age_gender_race_hba1c_treatement = age_gender_race_hba1c.merge(treatments, on='subject_id', how='left')\n",
        "\n",
        "# Replace NaN in the treatment-related columns with 'No Treatment'\n",
        "age_gender_race_hba1c_treatement.fillna({'prescriptions': 'NaN'}, inplace=True)"
      ],
      "metadata": {
        "id": "K-luNbvmuX4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting notes\n",
        "notes = extracting_notes(client, t2_diabetes_ids)\n",
        "\n",
        "# Assuming age_gender_race_hba1c_treatement and notes are already defined DataFrames\n",
        "complete_dataset = age_gender_race_hba1c_treatement.merge(notes, on='subject_id', how='left')"
      ],
      "metadata": {
        "id": "9kzbwmrtM9H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing GloVe to begin processing note embeddings\n",
        "import os\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve('https://nlp.stanford.edu/data/glove.6B.zip','glove.6B.zip')\n",
        "!unzip \"/content/glove.6B.zip\" -d \"/content/\"\n",
        "\n",
        "emmbed_dict = {}\n",
        "with open('/content/glove.6B.200d.txt','r') as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vector = np.asarray(values[1:],'float32')\n",
        "    emmbed_dict[word]=vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbiXrkdIT0Rc",
        "outputId": "b097ec7a-f57f-4ab1-d38b-e6ef2a449320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/glove.6B.zip\n",
            "replace /content/glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Methods to produce embedding for doctor's notes\n",
        "def preprocess_text(text):\n",
        "    # Simple tokenization and cleaning\n",
        "    tokens = text.lower().split()\n",
        "    # Remove placeholders and punctuation\n",
        "    tokens = [token.replace('_', '').replace(':', '').replace('.', '').replace(',', '') for token in tokens]\n",
        "    return tokens\n",
        "\n",
        "def get_text_vector(text, embedding_dict):\n",
        "    # Preprocess and tokenize the text\n",
        "    tokens = preprocess_text(text)\n",
        "    # Retrieve vectors for each token, ignoring out-of-vocabulary words\n",
        "    vectors = [embedding_dict[word] for word in tokens if word in embedding_dict]\n",
        "    # Handle case where no words had vectors (return zero vector)\n",
        "    if not vectors:\n",
        "        return np.zeros(next(iter(embedding_dict.values())).shape)\n",
        "    # Aggregate vectors (mean pooling in this example)\n",
        "    text_vector = np.mean(vectors, axis=0)\n",
        "    return text_vector\n",
        "\n",
        "def note_to_embedding(note):\n",
        "    # If the note is NaN (missing), return a zero vector\n",
        "    if pd.isna(note):\n",
        "        return np.zeros(200)\n",
        "    # Otherwise, get the text vector\n",
        "    return get_text_vector(note, emmbed_dict)"
      ],
      "metadata": {
        "id": "Llo18cl0T-g_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the function to each note and store the result in a new column\n",
        "complete_dataset['note_embedding'] = complete_dataset['first_note'].apply(note_to_embedding)"
      ],
      "metadata": {
        "id": "V6H-ExgLWLBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all column values and names to strings\n",
        "complete_dataset = complete_dataset.astype(str)\n",
        "complete_dataset.rename(columns={.25: 'percentile_25', .5: 'percentile_50', .75: 'percentile_75'}, inplace=True)\n",
        "\n",
        "# Upload the dataset to Google BigQuery table\n",
        "complete_dataset.to_gbq(destination_table='mimic_diabetes.patient_data',\n",
        "          project_id='agile-kite-406408',\n",
        "          if_exists='replace')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "leud50MjKLJ6",
        "outputId": "926bd092-8a76-4a12-f3c2-bb597b101594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ArrowTypeError",
          "evalue": "Expected a string or bytes dtype, got int64",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-192-48e1c849baa8>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Upload the dataset to Google BigQuery table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m complete_dataset.to_gbq(destination_table='mimic_diabetes.patient_data', \n\u001b[0m\u001b[1;32m      6\u001b[0m           \u001b[0mproject_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'agile-kite-406408'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           if_exists='replace')\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_gbq\u001b[0;34m(self, destination_table, project_id, chunksize, reauth, if_exists, auth_local_webserver, table_schema, location, progress_bar, credentials)\u001b[0m\n\u001b[1;32m   2168\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgbq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2170\u001b[0;31m         gbq.to_gbq(\n\u001b[0m\u001b[1;32m   2171\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2172\u001b[0m             \u001b[0mdestination_table\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/gbq.py\u001b[0m in \u001b[0;36mto_gbq\u001b[0;34m(dataframe, destination_table, project_id, chunksize, reauth, if_exists, auth_local_webserver, table_schema, location, progress_bar, credentials)\u001b[0m\n\u001b[1;32m    216\u001b[0m ) -> None:\n\u001b[1;32m    217\u001b[0m     \u001b[0mpandas_gbq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     pandas_gbq.to_gbq(\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mdestination_table\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas_gbq/gbq.py\u001b[0m in \u001b[0;36mto_gbq\u001b[0;34m(dataframe, destination_table, project_id, chunksize, reauth, if_exists, auth_local_webserver, table_schema, location, progress_bar, credentials, api_method, verbose, private_key, auth_redirect_uri, client_id, client_secret)\u001b[0m\n\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m     connector.load_data(\n\u001b[0m\u001b[1;32m   1221\u001b[0m         \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0mdestination_table_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas_gbq/gbq.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self, dataframe, destination_table_ref, write_disposition, chunksize, schema, progress_bar, api_method, billing_project)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             chunks = load.load_chunks(\n\u001b[0m\u001b[1;32m    603\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m                 \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas_gbq/load.py\u001b[0m in \u001b[0;36mload_chunks\u001b[0;34m(client, dataframe, destination_table_ref, chunksize, schema, location, api_method, write_disposition, billing_project)\u001b[0m\n\u001b[1;32m    241\u001b[0m ):\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mapi_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"load_parquet\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         load_parquet(\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas_gbq/load.py\u001b[0m in \u001b[0;36mload_parquet\u001b[0;34m(client, dataframe, destination_table_ref, write_disposition, location, schema, billing_project)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         client.load_table_from_dataframe(\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mdestination_table_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36mload_table_from_dataframe\u001b[0;34m(self, dataframe, destination, num_retries, job_id, job_id_prefix, location, project, job_config, parquet_compression, timeout)\u001b[0m\n\u001b[1;32m   2703\u001b[0m                         \u001b[0mparquet_compression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparquet_compression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2705\u001b[0;31m                     _pandas_helpers.dataframe_to_parquet(\n\u001b[0m\u001b[1;32m   2706\u001b[0m                         \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m                         \u001b[0mnew_job_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/bigquery/_pandas_helpers.py\u001b[0m in \u001b[0;36mdataframe_to_parquet\u001b[0;34m(dataframe, bq_schema, filepath, parquet_compression, parquet_use_compliant_nested_type)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0mbq_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_schema_fields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbq_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m     \u001b[0marrow_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe_to_arrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbq_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m     pyarrow.parquet.write_table(\n\u001b[1;32m    721\u001b[0m         \u001b[0marrow_table\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/bigquery/_pandas_helpers.py\u001b[0m in \u001b[0;36mdataframe_to_arrow\u001b[0;34m(dataframe, bq_schema)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0marrow_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbq_field\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         arrow_arrays.append(\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0mbq_to_arrow_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_column_or_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbq_field\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbq_field\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m         )\n\u001b[1;32m    664\u001b[0m         \u001b[0marrow_fields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbq_to_arrow_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbq_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrow_arrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/bigquery/_pandas_helpers.py\u001b[0m in \u001b[0;36mbq_to_arrow_array\u001b[0;34m(series, bq_field)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfield_type_upper\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_STRUCT_TYPES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStructArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrow_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrow_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.Array.from_pandas\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/masked.py\u001b[0m in \u001b[0;36m__arrow_array__\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mArrowTypeError\u001b[0m: Expected a string or bytes dtype, got int64"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uLuPe5wlxcAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# These are some util methods for testing IGNORE FOR MAIN FUNCTION\n",
        "def get_column_names(client, table_name):\n",
        "    query = f\"\"\"\n",
        "    SELECT column_name\n",
        "    FROM `physionet-data.mimiciv_hosp.INFORMATION_SCHEMA.COLUMNS`\n",
        "    WHERE table_name = '{table_name}'\n",
        "    \"\"\"\n",
        "    query_job = client.query(query)\n",
        "    results = query_job.result()\n",
        "\n",
        "    # Extract the column names\n",
        "    columns = [row.column_name for row in results]\n",
        "    return columns\n",
        "\n",
        "column_names = get_column_names(client, \"labevents\")\n",
        "print(column_names)\n",
        "\n",
        "def get_example_rows(client, table_name):\n",
        "    query = f\"\"\"\n",
        "    SELECT *\n",
        "    FROM `physionet-data.mimiciv_hosp.{table_name}`\n",
        "    LIMIT 5\n",
        "    \"\"\"\n",
        "    query_job = client.query(query)\n",
        "    results = query_job.result()\n",
        "\n",
        "    # Iterate over the rows and print them\n",
        "    for row in results:\n",
        "        print(row)\n",
        "\n",
        "# Now call the function\n",
        "get_example_rows(client, \"labevents\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cvi8bi7tjfU5",
        "outputId": "9b26225f-862e-426a-c656-b2671ec94004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['labevent_id', 'subject_id', 'hadm_id', 'specimen_id', 'itemid', 'order_provider_id', 'charttime', 'storetime', 'value', 'valuenum', 'valueuom', 'ref_range_lower', 'ref_range_upper', 'flag', 'priority', 'comments']\n",
            "Row((1058, 10000117, None, 25331308, 50965, 'P51F7B', datetime.datetime(2175, 1, 27, 16, 15), datetime.datetime(2175, 1, 27, 21, 11), '59', 59.0, 'pg/mL', 15.0, 65.0, None, 'ROUTINE', None), {'labevent_id': 0, 'subject_id': 1, 'hadm_id': 2, 'specimen_id': 3, 'itemid': 4, 'order_provider_id': 5, 'charttime': 6, 'storetime': 7, 'value': 8, 'valuenum': 9, 'valueuom': 10, 'ref_range_lower': 11, 'ref_range_upper': 12, 'flag': 13, 'priority': 14, 'comments': 15})\n",
            "Row((4784, 10000935, None, 69202241, 51010, 'P61VDC', datetime.datetime(2187, 2, 26, 8, 45), datetime.datetime(2187, 2, 26, 12, 41), '680', 680.0, 'pg/mL', 240.0, 900.0, None, 'ROUTINE', None), {'labevent_id': 0, 'subject_id': 1, 'hadm_id': 2, 'specimen_id': 3, 'itemid': 4, 'order_provider_id': 5, 'charttime': 6, 'storetime': 7, 'value': 8, 'valuenum': 9, 'valueuom': 10, 'ref_range_lower': 11, 'ref_range_upper': 12, 'flag': 13, 'priority': 14, 'comments': 15})\n",
            "Row((5472, 10000935, 25849114, 42157155, 50804, None, datetime.datetime(2187, 10, 22, 15, 40), datetime.datetime(2187, 10, 22, 15, 42), '22', 22.0, 'mEq/L', 21.0, 30.0, None, None, None), {'labevent_id': 0, 'subject_id': 1, 'hadm_id': 2, 'specimen_id': 3, 'itemid': 4, 'order_provider_id': 5, 'charttime': 6, 'storetime': 7, 'value': 8, 'valuenum': 9, 'valueuom': 10, 'ref_range_lower': 11, 'ref_range_upper': 12, 'flag': 13, 'priority': 14, 'comments': 15})\n",
            "Row((6211, 10000980, None, 46753637, 50910, None, datetime.datetime(2189, 6, 27, 6, 48), datetime.datetime(2189, 6, 27, 8, 59), '___', 303.0, 'IU/L', 29.0, 201.0, 'abnormal', 'STAT', 'NEW REFERENCE INTERVAL AS OF ___;UPPER LIMIT (97.5TH %ILE) VARIES WITH ANCESTRY AND GENDER (MALE/FEMALE);WHITES 322/201  BLACKS 801/414  ASIANS 641/313.'), {'labevent_id': 0, 'subject_id': 1, 'hadm_id': 2, 'specimen_id': 3, 'itemid': 4, 'order_provider_id': 5, 'charttime': 6, 'storetime': 7, 'value': 8, 'valuenum': 9, 'valueuom': 10, 'ref_range_lower': 11, 'ref_range_upper': 12, 'flag': 13, 'priority': 14, 'comments': 15})\n",
            "Row((7082, 10000980, None, 44394475, 50853, 'P29JE1', datetime.datetime(2191, 2, 20, 10, 0), datetime.datetime(2191, 2, 21, 8, 44), '___', 49.0, 'ng/mL', 30.0, 60.0, None, 'ROUTINE', 'NEW ASSAY IN USE ___: DETECTS D2 AND D3 25-OH ACCURATELY.'), {'labevent_id': 0, 'subject_id': 1, 'hadm_id': 2, 'specimen_id': 3, 'itemid': 4, 'order_provider_id': 5, 'charttime': 6, 'storetime': 7, 'value': 8, 'valuenum': 9, 'valueuom': 10, 'ref_range_lower': 11, 'ref_range_upper': 12, 'flag': 13, 'priority': 14, 'comments': 15})\n"
          ]
        }
      ]
    }
  ]
}